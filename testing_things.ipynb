{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8b72ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "from utils import *\n",
    "from modelADT import ModelADT\n",
    "from Generators import *\n",
    "from joint_model import Enc_2Dec_Network\n",
    "from joint_model import Enc_Dec_Network\n",
    "from params import *\n",
    "import trainer\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import h5py\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3e5c2047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################Custom DataLoader########################\n",
    "# Demands only a few Gigabytes of memory\n",
    "# `features_wo_offset`: targets for the consistency decoder\n",
    "# `features_w_offset` : inputs for the network/encoder\n",
    "# `labels_gaussian_2d`: targets for the location decoder\n",
    "class DLocDataset(Dataset):\n",
    "    \"\"\"DLoc dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dirs (list of strings): List of Directories with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        print(self.root_dir)\n",
    "        self.transform = transform\n",
    "        self.n_files = []\n",
    "        self.file_names = []\n",
    "        for n,i in enumerate(self.root_dir):\n",
    "            onlyfiles = next(os.walk(i))[2] #dir is your directory path as string\n",
    "            self.file_names.append([onlyfiles])\n",
    "            self.n_files.append(len(onlyfiles))\n",
    "\n",
    "    def __len__(self):\n",
    "        return np.sum(self.n_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        file_num = 0\n",
    "        count = 0\n",
    "        for dir_id, n_file in enumerate(self.n_files):\n",
    "            if idx[0] > (count+n_file):\n",
    "                count += n_file\n",
    "                continue\n",
    "            elif idx[-1] <= (count+n_file-1):\n",
    "                for i in idx:\n",
    "                    fname = self.file_names[dir_id][0][i-count]\n",
    "                    filename = os.path.join(self.root_dir[dir_id], fname)\n",
    "                    print(filename)\n",
    "                    f = h5py.File(filename,'r')\n",
    "                    f_wo_offset = np.transpose(np.array(f.get('features_wo_offset'), dtype=np.float32))\n",
    "                    f_w_offset = np.transpose(np.array(f.get('features_w_offset'), dtype=np.float32))\n",
    "                    labels_2d = np.transpose(np.array(f.get('labels_gaussian_2d'), dtype=np.float32))\n",
    "                    \n",
    "                    if ( file_num == 0) :\n",
    "                        features_wo_offset = f_wo_offset\n",
    "                        features_w_offset = f_w_offset\n",
    "                        labels_gaussian_2d = labels_2d\n",
    "                        file_num += 1\n",
    "                    else:\n",
    "                        features_wo_offset = np.concatenate((features_wo_offset, f_wo_offset),axis=0)\n",
    "                        features_w_offset = np.concatenate((features_w_offset, f_w_offset),axis=0)\n",
    "                        labels_gaussian_2d = np.concatenate((labels_gaussian_2d, labels_2d),axis=0)\n",
    "                    print(np.shape(labels_gaussian_2d))\n",
    "                    print(np.shape(features_wo_offset))\n",
    "                    print(np.shape(features_w_offset))\n",
    "                count += n_file\n",
    "                break\n",
    "            elif idx[-1] > (count+n_file-1):\n",
    "                for i in range(idx[0],count+n_file-1):\n",
    "#                     fname = str(i-count+1)+'.h5'\n",
    "                    fname = self.file_names[dir_id][0][i-count]\n",
    "                    filename = os.path.join(self.root_dir[dir_id], fname)\n",
    "                    print(filename)\n",
    "                    f = h5py.File(filename,'r')\n",
    "                    f_wo_offset = np.transpose(np.array(f.get('features_wo_offset'), dtype=np.float32))\n",
    "                    f_w_offset = np.transpose(np.array(f.get('features_w_offset'), dtype=np.float32))\n",
    "                    labels_2d = np.transpose(np.array(f.get('labels_gaussian_2d'), dtype=np.float32))\n",
    "                    \n",
    "                    if ( file_num == 0) :\n",
    "                        features_wo_offset = f_wo_offset\n",
    "                        features_w_offset = f_w_offset\n",
    "                        labels_gaussian_2d = labels_2d\n",
    "                        file_num += 1\n",
    "                    else:\n",
    "                        features_wo_offset = np.concatenate((features_wo_offset, f_wo_offset),axis=0)\n",
    "                        features_w_offset = np.concatenate((features_w_offset, f_w_offset),axis=0)\n",
    "                        labels_gaussian_2d = np.concatenate((labels_gaussian_2d, labels_2d),axis=0)\n",
    "                count += n_file\n",
    "                idx = np.array(idx)\n",
    "                idx = idx[np.array(idx)>=count].tolist()\n",
    "        features_wo_offset = np.squeeze(features_wo_offset)\n",
    "        features_w_offset = np.squeeze(features_w_offset)\n",
    "        if(len(np.shape(labels_gaussian_2d))==3):\n",
    "            if(np.shape(labels_gaussian_2d)[0]!=1):\n",
    "                labels_gaussian_2d = np.expand_dims(labels_gaussian_2d, axis=1)\n",
    "\n",
    "        sample = {'features_wo_offset': features_wo_offset, 'features_w_offset': features_w_offset, 'labels_gaussian_2d': labels_gaussian_2d}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "74ec75a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        features_wo_offset, features_w_offset, labels_gaussian_2d = sample['features_wo_offset'], sample['features_w_offset'], sample['labels_gaussian_2d']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C x H x W\n",
    "        return {'labels_gaussian_2d': torch.from_numpy(labels_gaussian_2d),\n",
    "                'features_wo_offset': torch.from_numpy(features_wo_offset),\n",
    "                'features_w_offset': torch.from_numpy(features_w_offset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "77c6c35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/media/datadisk/Roshan/datasets/DLoc_sim_data/features/jacobs_July28/', '/media/datadisk/Roshan/datasets/DLoc_sim_data/features/jacobs_July28_2/']\n"
     ]
    }
   ],
   "source": [
    "trainpath = ['/media/datadisk/Roshan/datasets/DLoc_sim_data/features/jacobs_July28/',\n",
    "             '/media/datadisk/Roshan/datasets/DLoc_sim_data/features/jacobs_July28_2/']\n",
    "\n",
    "\n",
    "\n",
    "train_data = DLocDataset(root_dir=trainpath,\n",
    "                                  transform=transforms.Compose([\n",
    "                                  ToTensor()\n",
    "                                  ]))\n",
    "train_loader =torch.utils.data.DataLoader(train_data, batch_size=opt_exp.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "97d70b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "[11440, 14732]\n",
      "26172\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_data.file_names))\n",
    "# print(train_data.file_names[2][0][2])\n",
    "# print(np.shape(train_data.file_names[0]))\n",
    "# print(np.shape(train_data.file_names[1]))\n",
    "# print(np.shape(train_data.file_names[2]))\n",
    "print(train_data.n_files)\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c28d7ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.DLocDataset object at 0x7f4fc7d9aa90>\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ff347fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/datadisk/Roshan/datasets/DLoc_sim_data/features/jacobs_July28/10.h5\n",
      "(1, 161, 361)\n",
      "(1, 4, 161, 361)\n",
      "(1, 4, 161, 361)\n",
      "Length of training data = 26172\n",
      "Size of features wo offset torch.Size([4, 161, 361])\n",
      "Size of features w offset  torch.Size([4, 161, 361])\n",
      "Size of labels             torch.Size([1, 161, 361])\n"
     ]
    }
   ],
   "source": [
    "sample = train_data[[1]]\n",
    "\n",
    "print('Length of training data = %d' % len(train_data))\n",
    "print(f\"Size of features wo offset {sample['features_wo_offset'].size()}\")\n",
    "print(f\"Size of features w offset  {sample['features_w_offset'].size()}\")\n",
    "print(f\"Size of labels             {sample['labels_gaussian_2d'].size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40a7530a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.h5\n"
     ]
    }
   ],
   "source": [
    "print(train_data.file_names[1][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "333725b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "818\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dd736d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897.625\n"
     ]
    }
   ],
   "source": [
    "print(28724/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bac359e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
